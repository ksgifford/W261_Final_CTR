{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Handling Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data and convert to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.sql.types import StructType, StructField, LongType\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql\n",
    "import pyspark.sql.functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store path to notebook\n",
    "PWD = !pwd\n",
    "PWD = PWD[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark Session\n",
    "app_name = \"categorical_notebook\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallRDD2 = sc.parallelize([(1,1), (2,1), (2,1), (3,1), (3,1), (3,1), (4,1), (4,1), (4,1), (4,1)])\n",
    "numColumns = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "structFieldList = [StructField('field_' + str(num), LongType(), True) for num in range(numColumns)]\n",
    "schema = StructType(structFieldList)\n",
    "testDF = spark.createDataFrame(smallRDD2, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the fields of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|field_0|\n",
      "+-------+\n",
      "|      1|\n",
      "|      2|\n",
      "|      2|\n",
      "|      3|\n",
      "|      3|\n",
      "|      3|\n",
      "|      4|\n",
      "|      4|\n",
      "|      4|\n",
      "|      4|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDF.select(['field_0']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oheForRow(value):\n",
    "\n",
    "    # Encode the rare / unseen value\n",
    "    if value not in valueDict:\n",
    "        oheList = [0] * len(valueDict)\n",
    "        oheList.append(1)\n",
    "        return oheList\n",
    "\n",
    "    oheList = []\n",
    "\n",
    "    # Encode values that have been seen\n",
    "    for key in valueDict.keys():\n",
    "        if key == value:\n",
    "            oheList.append(1)\n",
    "        else:\n",
    "            oheList.append(0)\n",
    "    \n",
    "    # Last column is for rare / unseen. Set to 0.\n",
    "    oheList.append(0)\n",
    "    \n",
    "    return oheList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oheDataFrame_fit(field, topN, df):\n",
    "\n",
    "    # Find the frequency of items in the category\n",
    "    fieldFreqRDD = df.rdd.map(lambda x: (x[field], 1)).\\\n",
    "                          reduceByKey(lambda x, y: x+y)\n",
    "\n",
    "    # Use the top N frequent values\n",
    "    valueCountList = fieldFreqRDD.takeOrdered(topN, key=lambda x: -x[1])\n",
    "    \n",
    "    # Add those values to a dictionary for OHE\n",
    "    for pair in valueCountList:\n",
    "        valueDict[pair[0]] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oheDataFrame_transform(field, df):\n",
    "\n",
    "    # Create a new RDD with the encoded values\n",
    "    oheRDD = df.rdd.map(lambda row: oheForRow(row[field]))\n",
    "\n",
    "    # Create a new DataFrame for the OHE RDD\n",
    "    structFieldList = [StructField(field + '_' + str(num), LongType(), True) for num in range(len(valueDict))]\n",
    "    structFieldList.append(StructField(field + '_UnkwnRare', LongType(), True))\n",
    "    schema = StructType(structFieldList)\n",
    "    oheDF = spark.createDataFrame(oheRDD, schema)\n",
    "    \n",
    "    # Add an index column\n",
    "    df = df.withColumn('id', pyspark.sql.functions.monotonically_increasing_id())\n",
    "    oheDF = oheDF.withColumn('id', pyspark.sql.functions.monotonically_increasing_id())\n",
    "\n",
    "    # Join the original DataFrame with the OHE DataFrame\n",
    "    #updatedDF = df.join(oheDF, df.id == oheDF.id, 'inner').drop(oheDF.id)\n",
    "    updatedDF = df.join(oheDF, ['id'])\n",
    "    \n",
    "    # Drop the original field that was OHE\n",
    "    updatedDF = updatedDF.drop(field)\n",
    "    updatedDF = updatedDF.drop('id')\n",
    "\n",
    "    return updatedDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary for the values to create new fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valueDict = {}\n",
    "fieldToEncode = 'field_0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the function to OHE the field to the number of specified fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "oheDataFrame_fit(fieldToEncode, 3, testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF3 = oheDataFrame_transform(fieldToEncode, testDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the DataFrame with the OHE fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------+---------+-----------------+\n",
      "|field_1|field_0_0|field_0_1|field_0_2|field_0_UnkwnRare|\n",
      "+-------+---------+---------+---------+-----------------+\n",
      "|      1|        0|        0|        0|                1|\n",
      "|      1|        0|        0|        1|                0|\n",
      "|      1|        0|        0|        1|                0|\n",
      "|      1|        0|        1|        0|                0|\n",
      "|      1|        0|        1|        0|                0|\n",
      "|      1|        0|        1|        0|                0|\n",
      "|      1|        1|        0|        0|                0|\n",
      "|      1|        1|        0|        0|                0|\n",
      "|      1|        1|        0|        0|                0|\n",
      "|      1|        1|        0|        0|                0|\n",
      "+-------+---------+---------+---------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDF3.orderBy('id').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
